version: "3"

services:
  namenode:
    image: docker-hadoop-namenode:1.0.0
    container_name: namenode
    hostname: namenode
    restart: always
    ports:
      - 9870:9870
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./namenode/000_run.sh:/postrun/000_run.sh
      - ./namenode/100_initialize.sh:/postrun/100_initialize.sh
      - ./spark:/opt/spark
      - hadoop_internamenode:/mnt/namenode/shared/
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      hadoop.net:
        aliases:
          - namenode.master
        
  
  # namenode2:
  #   image: docker-hadoop-namenode:1.0.0
  #   container_name: namenode2
  #   hostname: namenode2
  #   restart: always
  #   ports:
  #     - 9871:9870
  #   volumes:
  #     - hadoop_namenode2:/hadoop/dfs/name
  #     - ./namenode/000_run.sh:/postrun/000_run.sh
  #     - ./namenode/100_initialize.sh:/postrun/100_initialize.sh
  #     - ./spark:/opt/spark
  #     - hadoop_internamenode:/mnt/namenode/shared/
  #   environment:
  #     - CLUSTER_NAME=test
  #   env_file:
  #     - ./hadoop.env
  #   networks:
  #     - hadoop.net

  datanode1:
    image: docker-hadoop-datanode:1.0.0
    container_name: datanode1
    hostname: datanode1
    restart: always
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
      - ./datanode/001_datanode_run.sh:/postrun/001_datanode_run.sh
      - ./datanode/000_zookeeper_run.sh:/postrun/000_zookeeper_run.sh
      - ./datanode/zoo.cfg:/opt/zookeeper/conf/zoo.cfg
      - ./datanode/100_nodemanager_run.sh:/postrun/100_nodemanager_run.sh
      - ./spark:/opt/spark
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      MY_NODE_NUM: "1"
    env_file:
      - ./hadoop.env
    ports:
      - "9864:9864"
      - "8042:8042"
    networks:
      hadoop.net:
        aliases:
          - zk1.hadoop

  datanode2:
    image: docker-hadoop-datanode:1.0.0
    container_name: datanode2
    hostname: datanode2
    restart: always
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
      - ./datanode/001_datanode_run.sh:/postrun/001_datanode_run.sh
      - ./datanode/000_zookeeper_run.sh:/postrun/000_zookeeper_run.sh
      - ./datanode/zoo.cfg:/opt/zookeeper/conf/zoo.cfg
      - ./datanode/100_nodemanager_run.sh:/postrun/100_nodemanager_run.sh
      - ./spark:/opt/spark
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      MY_NODE_NUM: "2"
    env_file:
      - ./hadoop.env
    ports:
      - "9865:9864"
      - "8043:8042"
    networks:
      hadoop.net:
        aliases:
          - zk2.hadoop
  
  datanode3:
    image: docker-hadoop-datanode:1.0.0
    container_name: datanode3
    hostname: datanode3
    restart: always
    volumes:
      - hadoop_datanode3:/hadoop/dfs/data
      - ./datanode/001_datanode_run.sh:/postrun/001_datanode_run.sh
      - ./datanode/000_zookeeper_run.sh:/postrun/000_zookeeper_run.sh
      - ./datanode/zoo.cfg:/opt/zookeeper/conf/zoo.cfg
      - ./datanode/100_nodemanager_run.sh:/postrun/100_nodemanager_run.sh
      - ./spark:/opt/spark
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      MY_NODE_NUM: "3"
    env_file:
      - ./hadoop.env
    ports:
      - "9866:9864"
      - "8044:8042"
    networks:
      hadoop.net:
        aliases:
          - zk3.hadoop
  
  resourcemanager:
    image: docker-hadoop-resourcemanager:1.0.0
    container_name: resourcemanager
    hostname: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 datanode2:9864 datanode3:9864"
    env_file:
      - ./hadoop.env
    volumes:
      - ./resourcemanager/run.sh:/postrun/run.sh
    ports:
      - "8088:8088"
    networks:
      - hadoop.net 
  
  historyserver:
    image: docker-hadoop-historyserver:1.0.0
    container_name: historyserver
    hostname: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 datanode2:9864 datanode3:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
      - ./historyserver/001_run_yarn_hs.sh:/postrun/001_run_yarn_hs.sh
      - ./historyserver/002_run_spark_hs.sh:/postrun/002_run_spark_hs.sh
      - ./spark:/opt/spark
      - ./historyserver/spark_history_server.conf:/spark_history_server.conf
    env_file:
      - ./hadoop.env
    ports:
      - "8188:8188"
      - "18080:18080"
    networks:
      hadoop.net:
        aliases:
          - spark-historyserver
      
  hive-server:
    image: docker-hadoop-hive:1.0.0
    container_name: hive-server
    hostname: hive-server
    env_file:
      - ./hive/hadoop-hive.env
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "cluster-db:5432 namenode:9000 namenode:9870 datanode1:9864 datanode2:9864 datanode3:9864"
    volumes:
      - ./hive/100_hive_config.sh:/config/100_hive_config.sh
      - ./hive/999_startup.sh:/postrun/999_startup.sh
    ports:
      - "10000:10000"
      - "10001:10001"
      - "10002:10002"
    networks:
      hadoop.net:
        aliases:
          - hive-metastore

  cluster-db:
    image: postgres:13.1
    container_name: cluster-db
    hostname: cluster-db
    environment:
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_HOST_AUTH_METHOD: "trust"
    networks:
      - hadoop.net
    ports:
      - "5432:5432"
    volumes:
      - ./hive/sql/create_db.sql:/docker-entrypoint-initdb.d/create_hive_db.sql
      - ./hue/sql/create_db.sql:/docker-entrypoint-initdb.d/create_hue_db.sql
  
  hue:
    image: docker-hadoop-hue:1.0.0
    container_name: hue
    hostname: hue
    env_file:
      - ./hive/hadoop-hive.env
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "hive-server:10000"
    networks:
      - hadoop.net
    ports:
      - "8888:8888"

  trino:
    image: docker-hadoop-trino:1.0.0
    container_name: trino
    hostname: trino
    env_file:
      - ./hive/hadoop-hive.env
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "hive-server:10000"
    networks:
      - hadoop.net

  spark-adhoc:
    image: docker-hadoop-hive:1.0.0
    container_name: spark-adhoc
    hostname: spark-adhoc
    env_file:
      - ./hive/hadoop-hive.env
      - ./hadoop.env
    volumes:
      - ./spark:/opt/spark
      - ./hive/100_hive_config.sh:/config/100_hive_config.sh
      - ./spark-adhoc/run.sh:/postrun/run.sh
    environment:
      SERVICE_PRECONDITION: "hive-server:10000"
    ports:
      - "4040:4040"
    networks:
      - hadoop.net

volumes:
  hadoop_namenode:
  hadoop_namenode2:
  hadoop_internamenode:
  hadoop_datanode1:
  hadoop_datanode2:
  hadoop_datanode3:
  hadoop_historyserver:
  hadoop_trino:

networks:
  hadoop.net:
    external: true